% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Deduplicate.R
\name{deduplicateBam}
\alias{deduplicateBam}
\title{Deduplicate a folder of .bams by using UMIs}
\usage{
deduplicateBam(ncores = 1, bam.path, destination.prefix = "../BAM/", ...)
}
\arguments{
\item{ncores}{\code{integer} number of parallel processes to use. Be careful not to exceed the available memory--children processes appear to burst up to 2 gigs ram per million lines of .BAM to be read in at a time.  (You can control this by setting chunksize to a smaller value).}

\item{bam.path}{If provided, \code{character} giving the folder of input .bams.  If missing, then use the \code{RSEM} folder.}

\item{destination.prefix}{If provided, a \code{character} giving the folder of output .bams.  If missing, then use '../DEDUPLICATED_BAM' (evaluated relative to bam.path)}

\item{...}{additional arguments passed to \code{writeDeduplicatedBam}}
}
\value{
data.table with statistics
}
\description{
Each read is compared to an \emph{equivalence class} of reads that have the same mapping coordinates and UMI.
If the sequences match within a certain edit distance (see \code{getUniqueQname}), then all except one read (the highest quality read) are removed.
Note that for paired end reads, only the left-most (3 prime) mate will typically be compared in this process
}

